# backend/routers/video.py
from fastapi import APIRouter, UploadFile, File, BackgroundTasks, HTTPException
import os
import time
import aiofiles
import shutil
from config import UPLOAD_DIR, RESULT_DIR, MODEL_PATH
from db import SessionLocal
from models import DetectRecord
from ultralytics import YOLO
import cv2
import numpy as np
from collections import defaultdict, deque
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

router = APIRouter()

# åŠ è½½æ¨¡å‹
try:
    model = YOLO(MODEL_PATH)
    logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œæ”¯æŒ {len(model.names)} ä¸ªç±»åˆ«: {model.names}")
except Exception as e:
    logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    model = None


def process_video_perfect(input_path: str, output_path: str, conf: float = 0.5):
    """
    å®Œç¾çš„è§†é¢‘å¤„ç†å‡½æ•° - è§£å†³IDè·³å˜å’Œç»Ÿè®¡æ˜¾ç¤ºé—®é¢˜
    """
    if model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½æˆåŠŸ")

    logger.info(f"ğŸš€ å¼€å§‹è§†é¢‘å¤„ç†: {input_path} -> {output_path}")
    logger.info(f"âš™ï¸  é…ç½®: ç½®ä¿¡åº¦é˜ˆå€¼={conf}")

    start_time = time.time()

    # æ‰“å¼€è¾“å…¥è§†é¢‘
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        logger.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {input_path}")
        raise HTTPException(status_code=500, detail="æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS) or 25
    w, h = int(cap.get(3)), int(cap.get(4))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    logger.info(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {w}x{h}, FPS: {fps}, æ€»å¸§æ•°: {total_frames}")

    # åˆ›å»ºè¾“å‡ºè§†é¢‘
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))

    if not out.isOpened():
        cap.release()
        logger.error(f"âŒ æ— æ³•åˆ›å»ºè¾“å‡ºæ–‡ä»¶: {output_path}")
        raise HTTPException(status_code=500, detail="æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘æ–‡ä»¶")

    # ä½¿ç”¨ä¼˜åŒ–çš„è·Ÿè¸ªå‚æ•°
    results = model.track(
        source=input_path,
        imgsz=640,
        conf=0.2,
        iou=0.4,  # é€‚ä¸­çš„IOUé˜ˆå€¼ï¼Œå¹³è¡¡æ£€æµ‹ç²¾åº¦å’Œç¨³å®šæ€§
        persist=True,
        tracker="bytetrack.yaml",  # ä½¿ç”¨ByteTrackè·Ÿè¸ªå™¨
        verbose=False,
        stream=True  # æµå¼å¤„ç†ï¼ŒèŠ‚çœå†…å­˜
    )

    # è·Ÿè¸ªçŠ¶æ€ç®¡ç†
    active_tracks = {}  # å½“å‰æ´»è·ƒçš„è½¨è¿¹ {track_id: track_info}
    track_id_to_display_id = {}  # è·Ÿè¸ªIDåˆ°æ˜¾ç¤ºIDçš„æ˜ å°„
    next_display_id = 1
    consecutive_zero_frames = 0
    frame_stats_history = []

    # ç±»åˆ«é¢œè‰²æ˜ å°„
    color_map = {
        'person': (0, 255, 0),  # ç»¿è‰² - è¡Œäºº
        'car': (255, 0, 0),  # è“è‰² - æ±½è½¦
        'bicycle': (0, 255, 255),  # é»„è‰² - è‡ªè¡Œè½¦
        'motorcycle': (255, 255, 0),  # é’è‰² - æ‘©æ‰˜è½¦
        'truck': (255, 165, 0),  # æ©™è‰² - å¡è½¦
        'bus': (128, 0, 128),  # ç´«è‰² - å…¬äº¤è½¦
    }

    for frame_idx, result in enumerate(results):
        frame = result.orig_img.copy()

        # å½“å‰å¸§çš„ç»Ÿè®¡
        current_frame_stats = defaultdict(int)  # å½“å‰å¸§å„ç±»åˆ«æ•°é‡
        current_visible_tracks = set()  # å½“å‰å¸§å¯è§çš„è·Ÿè¸ªID

        # åŠ¨æ€è°ƒæ•´ç½®ä¿¡åº¦
        dynamic_conf = conf
        if consecutive_zero_frames > 10:  # è¿ç»­10å¸§æ— æ£€æµ‹
            dynamic_conf = max(0.1, conf * 0.5)  # å¤§å¹…é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
            logger.warning(f"âš ï¸ å¸§ {frame_idx}: è¿ç»­{consecutive_zero_frames}å¸§æ— æ£€æµ‹ï¼ŒåŠ¨æ€è°ƒæ•´ç½®ä¿¡åº¦åˆ°{dynamic_conf}")

        has_detections = False

        if result.boxes is not None:
            # è·å–æ£€æµ‹ç»“æœ
            if result.boxes.id is not None:
                boxes = result.boxes.xyxy.cpu().numpy()
                track_ids = result.boxes.id.cpu().numpy().astype(int)
                confidences = result.boxes.conf.cpu().numpy()
                class_ids = result.boxes.cls.cpu().numpy().astype(int)
            else:
                boxes = result.boxes.xyxy.cpu().numpy()
                confidences = result.boxes.conf.cpu().numpy()
                class_ids = result.boxes.cls.cpu().numpy().astype(int)
                track_ids = np.arange(len(boxes)) + frame_idx * 1000

            # ä½¿ç”¨åŠ¨æ€ç½®ä¿¡åº¦é˜ˆå€¼è¿›è¡Œè¿‡æ»¤
            valid_indices = confidences >= dynamic_conf
            boxes = boxes[valid_indices]
            track_ids = track_ids[valid_indices] if len(track_ids) == len(valid_indices) else track_ids
            class_ids = class_ids[valid_indices]
            confidences = confidences[valid_indices]

            # å¤„ç†æ£€æµ‹ç»“æœ
            for i, (box, track_id, confidence, class_id) in enumerate(zip(boxes, track_ids, confidences, class_ids)):
                x1, y1, x2, y2 = map(int, box)
                class_name = model.names[int(class_id)]

                # æ”¾å®½é¢ç§¯è¿‡æ»¤æ¡ä»¶
                bbox_area = (x2 - x1) * (y2 - y1)
                min_area = 100  # ä»300é™ä½åˆ°100ï¼Œæ£€æµ‹æ›´å°ç›®æ ‡
                max_area = w * h * 0.8  # é¿å…è¿‡å¤§çš„è¯¯æ£€

                if bbox_area < min_area or bbox_area > max_area:
                    continue

                has_detections = True
                current_visible_tracks.add(track_id)
                current_frame_stats[class_name] += 1

                # é¢œè‰²å’Œæ˜¾ç¤ºIDç®¡ç†
                color = (0, 255, 0) if class_name == 'person' else (255, 0, 0)

                if track_id not in track_id_to_display_id:
                    track_id_to_display_id[track_id] = next_display_id
                    next_display_id += 1

                display_id = track_id_to_display_id[track_id]

                # ç»˜åˆ¶æ£€æµ‹æ¡†
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                label = f"{class_name[0].upper()}{display_id}"
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]

                # æ ‡ç­¾èƒŒæ™¯
                cv2.rectangle(frame, (x1, y1 - label_size[1] - 8),
                              (x1 + label_size[0] + 5, y1), color, -1)
                cv2.putText(frame, label, (x1 + 2, y1 - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                # æ›´æ–°æ´»è·ƒè½¨è¿¹
                active_tracks[track_id] = {
                    'class': class_name,
                    'last_seen': frame_idx,
                    'display_id': display_id
                }

        # æ›´æ–°è¿ç»­é›¶æ£€æµ‹è®¡æ•°å™¨
        if has_detections:
            consecutive_zero_frames = 0  # é‡ç½®è®¡æ•°å™¨
        else:
            consecutive_zero_frames += 1

        # æ¸…ç†è¿‡æœŸè½¨è¿¹ï¼ˆä½†ä¸è¦è¿‡äºæ¿€è¿›ï¼‰
        tracks_to_remove = []
        current_time = frame_idx
        for track_id, info in list(active_tracks.items()):
            # å»¶é•¿è½¨è¿¹ä¿ç•™æ—¶é—´ï¼Œä»50å¸§å¢åŠ åˆ°100å¸§
            if current_time - info['last_seen'] > 100:
                tracks_to_remove.append(track_id)

        for track_id in tracks_to_remove:
            if track_id in active_tracks:
                del active_tracks[track_id]

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
        visible_count = sum(current_frame_stats.values())

        # åœ¨ç”»é¢ä¸Šæ˜¾ç¤ºæ›´è¯¦ç»†çš„åˆ†æä¿¡æ¯
        stats_background_height = 90
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (500, stats_background_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)

        # ä¸»ç»Ÿè®¡è¡Œ
        progress = (frame_idx / total_frames * 100) if total_frames > 0 else 0
        main_stats = f"Frame: {frame_idx} ({progress:.1f}%) | Visible: {visible_count} | Conf: {dynamic_conf:.2f}"
        cv2.putText(frame, main_stats, (10, 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        # æ£€æµ‹çŠ¶æ€è¡Œ
        status_color = (0, 255, 0) if visible_count > 0 else (0, 165, 255)  # ç»¿è‰²/æ©™è‰²
        status_text = "DETECTING" if visible_count > 0 else f"NO DETECT{consecutive_zero_frames}f"
        cv2.putText(frame, status_text, (10, 45),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 2)

        # å„ç±»åˆ«ç»Ÿè®¡
        if current_frame_stats:
            classes_text = " | ".join([f"{k}:{v}" for k, v in current_frame_stats.items()])
            cv2.putText(frame, classes_text, (10, 70),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        else:
            cv2.putText(frame, "NO OBJECTS", (10, 70),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)

        # è·Ÿè¸ªä¿¡æ¯
        tracking_info = f"Active Tracks: {len(active_tracks)}"
        cv2.putText(frame, tracking_info, (10, 85),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 1)

        out.write(frame)

        # å¢å¼ºçš„æ—¥å¿—è¾“å‡º
        if frame_idx % 50 == 0 or consecutive_zero_frames > 5:
            log_level = logging.WARNING if consecutive_zero_frames > 10 else logging.INFO
            logger.log(log_level,
                       f"å¸§ {frame_idx}: å¯è§{visible_count}ç›®æ ‡, è¿ç»­é›¶æ£€æµ‹: {consecutive_zero_frames}å¸§, ç½®ä¿¡åº¦: {dynamic_conf:.2f}")

        # è®°å½•å†å²ç”¨äºåˆ†æ
        frame_stats_history.append({
            'frame': frame_idx,
            'visible': visible_count,
            'classes': dict(current_frame_stats),
            'consecutive_zeros': consecutive_zero_frames
        })

    # æœ€ç»ˆåˆ†æå’ŒæŠ¥å‘Š
    end_time = time.time()
    processing_time = end_time - start_time

    cap.release()
    out.release()

    # åˆ†ææ£€æµ‹ç»“æœ
    total_frames_processed = len(frame_stats_history)
    zero_detection_frames = sum(1 for stats in frame_stats_history if stats['visible'] == 0)
    zero_percentage = (zero_detection_frames / total_frames_processed * 100) if total_frames_processed > 0 else 0

    logger.info(f"ğŸ“Š æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
    logger.info(f"   æ€»å¸§æ•°: {total_frames_processed}")
    logger.info(f"   é›¶æ£€æµ‹å¸§æ•°: {zero_detection_frames} ({zero_percentage:.1f}%)")
    logger.info(f"   æ€»è·Ÿè¸ªç›®æ ‡: {len(track_id_to_display_id)}")
    logger.info(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")

    if zero_percentage > 50:
        logger.warning(f"âš ï¸ é«˜é›¶æ£€æµ‹ç‡({zero_percentage:.1f}%)ï¼Œå»ºè®®æ£€æŸ¥è§†é¢‘å†…å®¹æˆ–è°ƒæ•´æ£€æµ‹å‚æ•°")

    return {
        "total_frames": total_frames_processed,
        "zero_detection_frames": zero_detection_frames,
        "zero_percentage": zero_percentage,
        "total_tracks": len(track_id_to_display_id),
        "processing_time": processing_time  # æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
    }


@router.post("/detect/video")
async def detect_video(
        file: UploadFile = File(...),
        background_tasks: BackgroundTasks = None,
        conf: float = 0.3
):
    """
    å®Œç¾çš„è§†é¢‘æ£€æµ‹æ¥å£
    """
    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    suffix = os.path.splitext(file.filename)[1].lower()
    if suffix not in [".mp4", ".avi", ".mov", ".mkv"]:
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼")

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
    if model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„")

    # åˆ›å»ºå”¯ä¸€æ–‡ä»¶å
    timestamp = int(time.time() * 1000)
    save_name = f"{timestamp}_{file.filename}"
    save_path = os.path.join(UPLOAD_DIR, save_name)

    # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    os.makedirs(RESULT_DIR, exist_ok=True)

    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    try:
        async with aiofiles.open(save_path, "wb") as out_file:
            content = await file.read()
            await out_file.write(content)
        logger.info(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜: {save_path} ({len(content)} bytes)")
    except Exception as e:
        logger.error(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ–‡ä»¶ä¿å­˜å¤±è´¥")

    # å‡†å¤‡è¾“å‡ºè·¯å¾„
    out_name = f"res_{save_name}.mp4"
    out_path = os.path.join(RESULT_DIR, out_name)

    def _bg_task():
        """åå°å¤„ç†ä»»åŠ¡"""
        try:
            logger.info(f"ğŸ”§ å¼€å§‹åå°å¤„ç†ä»»åŠ¡...")

            # å¤„ç†è§†é¢‘
            result_info = process_video_perfect(save_path, out_path, conf=conf)

            # ä¿å­˜åˆ°æ•°æ®åº“
            db = SessionLocal()
            try:
                record = DetectRecord(
                    type="video",
                    filename=save_name,
                    source_path=save_path,
                    result_path=out_path,
                    objects=[],
                    processing_time=result_info["processing_time"],  # ç°åœ¨æœ‰è¿™ä¸ªå­—æ®µäº†
                    total_frames=result_info["total_frames"]  # ç°åœ¨æœ‰è¿™ä¸ªå­—æ®µäº†
                )
                db.add(record)
                db.commit()
                logger.info(f"ğŸ’¾ æ•°æ®åº“è®°å½•å·²ä¿å­˜")
            except Exception as db_error:
                logger.error(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {db_error}")
                db.rollback()
            finally:
                db.close()

            logger.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ: {out_path}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(save_path):
                try:
                    os.remove(save_path)
                    logger.info(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {save_path}")
                except:
                    pass

    # æäº¤åå°ä»»åŠ¡
    if background_tasks:
        background_tasks.add_task(_bg_task)
        logger.info(f"ğŸ“‹ åå°ä»»åŠ¡å·²æäº¤")
    else:
        # å¦‚æœæ²¡æœ‰background_tasksï¼Œç›´æ¥è¿è¡Œï¼ˆå¼€å‘æµ‹è¯•ç”¨ï¼‰
        logger.warning("âš ï¸  ç›´æ¥è¿è¡Œå¤„ç†ä»»åŠ¡ï¼ˆæ— åå°ä»»åŠ¡ï¼‰")
        _bg_task()

    return {
        "status": "processing",
        "result_url": f"/api/files/result/{out_name}",
        "message": "è§†é¢‘æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºäº†è§£è¿›åº¦",
        "config": {
            "confidence_threshold": conf,
            "filename": save_name,
            "estimated_time": "å–å†³äºè§†é¢‘é•¿åº¦å’Œå¤æ‚åº¦"
        }
    }


@router.get("/model/classes")
async def get_model_classes():
    """
    è·å–æ¨¡å‹æ”¯æŒçš„ç±»åˆ«åˆ—è¡¨
    """
    if model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")

    return {
        "model_classes": model.names,
        "class_count": len(model.names),
        "supported_classes": {i: name for i, name in model.names.items()}
    }


@router.get("/model/info")
async def get_model_info():
    """
    è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯
    """
    if model is None:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")

    return {
        "model_path": MODEL_PATH,
        "model_type": str(type(model.model)),
        "class_count": len(model.names),
        "classes": model.names
    }


@router.get("/test/processing")
async def test_processing():
    """
    æµ‹è¯•å¤„ç†åŠŸèƒ½çš„ç«¯ç‚¹
    """
    logger.info("ğŸ§ª æµ‹è¯•å¤„ç†åŠŸèƒ½...")

    # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¥å¿—
    for i in range(5):
        logger.info(f"æµ‹è¯•æ—¥å¿— {i + 1}/5")
        time.sleep(0.5)

    return {
        "status": "success",
        "message": "å¤„ç†æµ‹è¯•å®Œæˆï¼Œè¯·æ£€æŸ¥æ§åˆ¶å°è¾“å‡º",
        "test_data": {
            "frames_processed": 100,
            "objects_detected": 25,
            "processing_time": 2.5
        }
    }